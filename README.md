# Lunar Lander — Double DQN (PyTorch)

A compact Double-DQN implementation (PyTorch) that trains an agent to solve the OpenAI Gymnasium "LunarLander-v3" environment. This repository includes training and evaluation scripts, a saved model checkpoint, a replay buffer, a simple neural network, and utilities to record videos and plot training curves.

Last updated: 2025-12-28

## Features

- Double-DQN style target computation (online network selects action; target network evaluates)
- Replay buffer with uniform sampling
- Target network with periodic hard updates
- Training loop and evaluation utilities
- Save / load model checkpoint (dqn_lunarlander.pth included)
- Evaluation recordings saved to `videos/`
- Training reward plot `training_curve.png`

## Requirements

This project was developed with Python 3.8+ and the following packages (see `requirements.txt`):

- torch
- gymnasium (LunarLander-v3)
- box2d-py (or system-appropriate Box2D bindings)
- numpy (<2)
- matplotlib
- pyyaml

Note: main.py imports `gymnasium` as `gym`. If you encounter Box2D or rendering issues, install the Box2D extras for your environment (for example: `pip install gymnasium[box2d]` or `pip install box2d-py`).

## Quickstart

1. Clone the repo

   git clone https://github.com/narendrapatel6321-dotcom/Lunar-Lander.git
   cd Lunar-Lander

2. (Optional) Create and activate a virtual environment

   python -m venv .venv
   # macOS / Linux
   source .venv/bin/activate
   # Windows (PowerShell)
   .\.venv\Scripts\Activate.ps1

3. Install dependencies

   pip install -r requirements.txt

4. Run the project

   python main.py

By default, `main.py` runs in evaluation mode (TRAIN = False), loads the checkpoint `dqn_lunarlander.pth`, and records evaluation episodes to the `videos/` directory.

## Training

To train the agent:

- Open `main.py` and set `TRAIN = True`.
- Adjust hyperparameters in the `Agent` constructor call if desired (learning rate, epsilon decay, etc.).
- Run:

  python main.py

Training (as currently configured) executes `train(agent, train_env, episodes=10000)`, saves the training rewards plot to `training_curve.png`, and saves the trained model to `dqn_lunarlander.pth`.

Training can take significant time depending on hardware; reduce the number of episodes or tune hyperparameters for quicker experiments.

## Evaluation

When `TRAIN = False`, `main.py`:

- Loads `dqn_lunarlander.pth` (agent.load)
- Wraps the evaluation environment with `RecordVideo` and saves videos to `videos/`
- Runs `evaluate(agent, eval_env, episodes=5)`

To change the number of evaluation episodes or recording behavior, edit `main.py`.

## Files / Project Structure

- main.py                 — Entry point (toggle training/evaluation)
- agent.py                — Agent class: networks, optimizer, train_step, save/load
- network.py              — Simple neural network (PyTorch)
- replay_buffer.py        — ReplayBuffer implementation
- helpers.py              — train(), evaluate(), plotting utilities
- requirements.txt        — Project dependencies
- dqn_lunarlander.pth     — Saved model checkpoint (included)
- training_curve.png      — Example training reward curve
- videos/                 — Generated by evaluation recordings

## Key implementation details & hyperparameters

- Discount factor (gamma): 0.99
- Optimizer: Adam
- Learning rate: default used in `main.py` is 5e-4
- Epsilon greedy: start=1.0, final=0.05, decay controlled by `epsilon_decay`
- Replay buffer size: 100,000 (default)
- Batch size: 32
- Target network hard update frequency: 1000 steps
- Loss: MSELoss
- Gradient clipping: clip gradients to norm 1.0

Double-DQN behavior: online network selects the next action (argmax), and the target network provides the Q-value for that chosen action when computing the bootstrap target.

## Notes & Troubleshooting

- If you get "gymnasium" vs "gym" import errors, install `gymnasium` and the Box2D extras. Some environments (platform or gym version) may require `box2d-py` or `Box2D`.
- If video recording fails, ensure ffmpeg is installed on your system and that the rendering mode is supported.
- To re-record evaluation videos, remove or rename the `videos/` folder or change the `name_prefix` in `main.py`.


## Contact

Repository owner: narendrapatel6321-dotcom
GitHub: https://github.com/narendrapatel6321-dotcom/Lunar-Lander
